{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "with open('data/internet_archive_scifi_v3.txt') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' One of his hands twitched, came up almost to his face as though to shield hiseyes, then dropped limply back. \"That light -- \" he mumbled. \" -- stays on , # Kirk said briskly. # The quicker you tell us the answers, the quicker we all relax. Okay?\" Cordell shook his head numbly, not so much in negation as an effort to clear the fog from his tortured mind. T told you,\" he cried hoarsely. \"What rpofe do you want? Yesterday I told you the whole thing.\" His voice began to border on hysteria. \"What good\\'s my trying to tell you if you won\\'t listen? How\\'s a guy supposed -- \" \"Then try telling it straight!\" Kirk snapped. \"You think you\\'re fooling around with half-wits? Sure ; you told us. A crazy pack of goof-ball dreams about a blonde babe clubbing two grown people to death, then disappearing in a ball of blue light! You figure on copping a plea on insanity?\" \"It\\'s the truth!\" Cordell shouted. \"As God hears me, it\\'s true!\" Suddenly he buried his face in his hands and long tearing sobs shook hi'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "text[9000:10000]  # print few texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = tuple(set(text[580:]))  # scifi text starts from character no '580'\n",
    "int2char = dict(enumerate(chars))  # maps integers to characters\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}  # maps characters to unique integers\n",
    "encoding = np.array([char2int[ch] for ch in text])  # encodes the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ttokens:\n('H', '?', 'N', 'G', '!', 'c', '#', 'O', 'V', 'u', 'U', 'n', 'm', 'v', 'J', ',', '-', '8', 'D', '6', 'B', '.', 'S', 'P', 'e', 'X', '\"', 'i', 'I', 'd', 'f', 'z', 'j', 'w', 'p', 'y', '5', ':', 'g', 'R', 'F', 't', 'a', 's', '(', 'b', 'l', '7', '2', 'k', 'K', \"'\", '9', 'T', 'M', 'C', ')', '3', 'r', 'h', 'Y', 'Z', 'L', ' ', 'E', 'x', ';', '1', 'W', '0', 'Q', 'o', '4', 'A', 'q')\n\n    \tinteger to character mapping:\n{0: 'H', 1: '?', 2: 'N', 3: 'G', 4: '!', 5: 'c', 6: '#', 7: 'O', 8: 'V', 9: 'u', 10: 'U', 11: 'n', 12: 'm', 13: 'v', 14: 'J', 15: ',', 16: '-', 17: '8', 18: 'D', 19: '6', 20: 'B', 21: '.', 22: 'S', 23: 'P', 24: 'e', 25: 'X', 26: '\"', 27: 'i', 28: 'I', 29: 'd', 30: 'f', 31: 'z', 32: 'j', 33: 'w', 34: 'p', 35: 'y', 36: '5', 37: ':', 38: 'g', 39: 'R', 40: 'F', 41: 't', 42: 'a', 43: 's', 44: '(', 45: 'b', 46: 'l', 47: '7', 48: '2', 49: 'k', 50: 'K', 51: \"'\", 52: '9', 53: 'T', 54: 'M', 55: 'C', 56: ')', 57: '3', 58: 'r', 59: 'h', 60: 'Y', 61: 'Z', 62: 'L', 63: ' ', 64: 'E', 65: 'x', 66: ';', 67: '1', 68: 'W', 69: '0', 70: 'Q', 71: 'o', 72: '4', 73: 'A', 74: 'q'}\n\n    \tcharacter to integer mapping:\n{'H': 0, '?': 1, 'N': 2, 'G': 3, '!': 4, 'c': 5, '#': 6, 'O': 7, 'V': 8, 'u': 9, 'U': 10, 'n': 11, 'm': 12, 'v': 13, 'J': 14, ',': 15, '-': 16, '8': 17, 'D': 18, '6': 19, 'B': 20, '.': 21, 'S': 22, 'P': 23, 'e': 24, 'X': 25, '\"': 26, 'i': 27, 'I': 28, 'd': 29, 'f': 30, 'z': 31, 'j': 32, 'w': 33, 'p': 34, 'y': 35, '5': 36, ':': 37, 'g': 38, 'R': 39, 'F': 40, 't': 41, 'a': 42, 's': 43, '(': 44, 'b': 45, 'l': 46, '7': 47, '2': 48, 'k': 49, 'K': 50, \"'\": 51, '9': 52, 'T': 53, 'M': 54, 'C': 55, ')': 56, '3': 57, 'r': 58, 'h': 59, 'Y': 60, 'Z': 61, 'L': 62, ' ': 63, 'E': 64, 'x': 65, ';': 66, '1': 67, 'W': 68, '0': 69, 'Q': 70, 'o': 71, '4': 72, 'A': 73, 'q': 74}\n\n    \ttotal no of unique characters: 75\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'\\ttokens:\\n{chars}\\n\\n\\\n",
    "    \\tinteger to character mapping:\\n{int2char}\\n\\n\\\n",
    "    \\tcharacter to integer mapping:\\n{char2int}\\n\\n\\\n",
    "    \\ttotal no of unique characters: {len(chars)}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([54, 73, 39, 55,  0, 63,  6, 63, 73, 46, 46, 63, 22, 41, 71, 58, 27,\n",
       "       24, 43, 63,  2, 24, 33, 63, 42, 11, 29, 63, 55, 71, 12, 34, 46, 24,\n",
       "       41, 24, 63, 23,  9, 45, 46, 27, 43, 59, 24, 58, 63, 64, 29, 27, 41,\n",
       "       71, 58, 63, 28, 40, 63, 27, 43, 63, 34,  9, 45, 46, 27, 43, 59, 24,\n",
       "       29, 63, 45, 27, 16, 12, 71, 11, 41, 59, 46, 35, 63, 45, 35, 63, 70,\n",
       "        9, 27, 11, 11, 63, 23,  9, 45, 46, 27, 43, 59, 27, 11, 38])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "encoding[:100]  # to see how characters are into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "149326361"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "len(encoding)  # total no of characters in the dataset (~150M)"
   ]
  }
 ]
}